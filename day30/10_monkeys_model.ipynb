{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from deeplearning_model import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from deeplearning_model import evaluate_classification_model as evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./archive/\")\n",
    "\n",
    "# 定义数据预处理\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 使用ImageFolder加载数据\n",
    "# ImageFolder假设数据集按照如下方式组织：root/class/image.jpg\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=DATA_DIR / 'training',\n",
    "    transform=data_transforms['training']\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=DATA_DIR / 'validation',\n",
    "    transform=data_transforms['validation']\n",
    ")\n",
    "\n",
    "# 打印类别信息\n",
    "class_names = train_dataset.classes\n",
    "print(f\"类别数量: {len(class_names)}\")\n",
    "print(f\"类别名称: {class_names}\")\n",
    "\n",
    "# 查看一个样本\n",
    "img, label = train_dataset[0]\n",
    "print(f\"图像形状: {img.shape}\")  # 应该是[3, 128, 128]\n",
    "print(f\"标签: {label} (类别: {class_names[label]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义数据集类，继承ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./archive/\")\n",
    "\n",
    "# 自定义数据集类，继承ImageFolder\n",
    "class MonkeyDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root=root, transform=transform)\n",
    "        \n",
    "\n",
    "# 定义数据预处理\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.4363, 0.4328, 0.3291], std=[0.2085, 0.2032, 0.1988])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.4363, 0.4328, 0.3291], std=[0.2085, 0.2032, 0.1988])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 使用自定义的MonkeyDataset加载数据\n",
    "train_dataset = MonkeyDataset(\n",
    "    root=DATA_DIR / 'training',\n",
    "    transform=data_transforms['training']\n",
    ")\n",
    "\n",
    "test_dataset = MonkeyDataset(\n",
    "    root=DATA_DIR / 'validation',\n",
    "    transform=data_transforms['validation']\n",
    ")\n",
    "\n",
    "# 打印类别信息\n",
    "class_names = train_dataset.classes\n",
    "print(f\"类别数量: {len(class_names)}\")\n",
    "print(f\"类别名称: {class_names}\")\n",
    "\n",
    "# 查看一个样本\n",
    "img, label = train_dataset[0]\n",
    "print(f\"图像形状: {img.shape}\")  # 应该是[3, 128, 128]\n",
    "print(f\"标签: {label} (类别: {class_names[label]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算train_dataset的均值和方差，做数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds:\n",
    "        mean += img.mean(dim=(1, 2)) #dim=(1, 2)表示在通道维度上求平均\n",
    "        std += img.std(dim=(1, 2))  #dim=(1, 2)表示在通道维度上求标准差\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "cal_mean_std(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 打印数据集大小信息\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建模型，定义CNN卷积模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 第一个卷积块：3通道输入，32通道输出\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 输入图像为3通道，输出32个特征图\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)  # 保持通道数不变，增强特征提取\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 最大池化层，减小特征图尺寸\n",
    "        \n",
    "        # 第二个卷积块：32通道输入，64通道输出\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 增加通道数到64，提取更复杂特征\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)  # 保持通道数不变，进一步提取特征\n",
    "        \n",
    "        # 第三个卷积块：64通道输入，128通道输出\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 增加通道数到128，提取高级特征\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)  # 保持通道数不变，进一步提取特征\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)  # 将特征图展平后连接到256个神经元\n",
    "        self.dropout = nn.Dropout(0.2) # 添加Dropout层，防止过拟合\n",
    "        self.fc2 = nn.Linear(256, 10)  # 输出层，10个类别（猴子种类）\n",
    "        \n",
    "        # 初始化网络权重\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        # 使用Xavier初始化方法初始化权重\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)  \n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)  # 偏置初始化为0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 第一个卷积块\n",
    "        x = F.relu(self.conv1(x))  # 第一次卷积后激活\n",
    "        x = F.relu(self.conv2(x))  # 第二次卷积后激活\n",
    "        x = self.pool(x)  # 池化减小尺寸\n",
    "        \n",
    "        # 第二个卷积块\n",
    "        x = F.relu(self.conv3(x))  \n",
    "        x = F.relu(self.conv4(x))  \n",
    "        x = self.pool(x)  # 池化减小尺寸\n",
    "        \n",
    "        # 第三个卷积块\n",
    "        x = F.relu(self.conv5(x))  \n",
    "        x = F.relu(self.conv6(x))  \n",
    "        x = self.pool(x)  # 池化减小尺寸\n",
    "        \n",
    "        # 展平特征图\n",
    "        x = x.view(x.size(0), -1)  # 将特征图展平为一维向量\n",
    "        \n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))  # 第一个全连接层后激活\n",
    "        x = F.dropout(x, p=0.2, training=self.training)  # 添加Dropout层，有20%的节点被丢弃\n",
    "        x = self.fc2(x)  # 输出层，不使用激活函数\n",
    "        \n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
