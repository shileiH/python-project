{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 创建张量的不同方法：\n",
      "从列表创建: tensor([1, 2, 3])\n",
      "从NumPy数组创建: tensor([4, 5, 6], dtype=torch.int32)\n",
      "全0张量:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "全1张量:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "随机张量:\n",
      "tensor([[0.2959, 0.0606],\n",
      "        [0.3224, 0.0399]])\n",
      "未初始化张量: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 创建张量的不同方法\n",
    "print(\"创建张量的不同方法：\")\n",
    "x = torch.tensor([1, 2, 3],dtype=torch.float32)  # 从列表创建张量\n",
    "print(f\"从列表创建,可指定数据类型: {x}\")\n",
    "\n",
    "y = torch.from_numpy(np.array([4, 5, 6]))  # 从NumPy数组创建张量\n",
    "print(f\"从NumPy数组创建: {y}\")\n",
    "\n",
    "z = torch.zeros(3, 4)  # 创建全0张量\n",
    "print(f\"全0张量:\\n{z}\")\n",
    "\n",
    "ones = torch.ones(2, 3)  # 创建全1张量\n",
    "print(f\"全1张量:\\n{ones}\")\n",
    "\n",
    "rand_tensor = torch.rand(2, 2)  # 创建随机张量(0-1均匀分布)\n",
    "print(f\"随机张量:\\n{rand_tensor}\")\n",
    "\n",
    "# 创建未初始化的张量\n",
    "empty_tensor = torch.empty(2, 3)\n",
    "print(\"未初始化张量:\", empty_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. 张量的维度操作：\n",
      "原始张量:\n",
      "tensor([[0.8984, 0.8042, 0.7931],\n",
      "        [0.2995, 0.0177, 0.1964]])\n",
      "转置后:\n",
      "tensor([[0.8984, 0.2995],\n",
      "        [0.8042, 0.0177],\n",
      "        [0.7931, 0.1964]])\n",
      "重塑后形状: torch.Size([4, 6])\n",
      "视图(共享数据):\n",
      "tensor([[9.9753e-01, 8.4997e-01, 3.5172e-01, 6.7017e-01, 9.0693e-01, 9.6868e-01],\n",
      "        [8.5565e-02, 8.1011e-01, 2.2763e-01, 3.5793e-01, 7.0218e-01, 9.8127e-01],\n",
      "        [3.7074e-04, 9.5176e-01, 7.7234e-01, 4.8474e-01, 5.8474e-01, 1.8669e-01],\n",
      "        [5.2942e-01, 5.9628e-01, 9.0672e-01, 5.4176e-01, 7.1012e-01, 6.6131e-01]])\n",
      "展平后: torch.Size([24])\n",
      "维度扩展: torch.Size([1, 2, 3, 4])\n",
      "维度压缩: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 张量的维度操作\n",
    "print(\"张量的维度操作：\")\n",
    "tensor = torch.rand(2, 3)\n",
    "print(f\"原始张量:\\n{tensor}\")\n",
    "print(f\"转置后:\\n{tensor.t()}\")\n",
    "\n",
    "tensor = torch.rand(2, 3, 4)\n",
    "# 形状变换\n",
    "reshaped = tensor.reshape(4, 6)\n",
    "print(\"重塑后形状:\", reshaped.shape)\n",
    "print(f\"视图(共享数据):\\n{tensor.view(4, 6)}\")\n",
    "print(\"展平后:\", tensor.flatten().shape)\n",
    "print(\"维度扩展:\", tensor.unsqueeze(0).shape)  # 在第0维添加维度\n",
    "print(\"维度压缩:\", tensor[:, 0:1, :].squeeze(1).shape)  # 压缩大小为1的维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. 张量的基本属性：\n",
      "张量形状: torch.Size([3, 4, 5])\n",
      "张量维度数: 3\n",
      "张量元素总数: 60\n",
      "张量数据类型: torch.float32\n",
      "张量所在设备: cpu\n",
      "\n",
      "3. 张量的索引和切片：\n",
      "原始张量:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "第一行: tensor([1, 2, 3])\n",
      "第一列: tensor([1, 4, 7])\n",
      "子矩阵:\n",
      "tensor([[2, 3],\n",
      "        [5, 6]])\n",
      "\n",
      "4. 张量的数学运算：\n",
      "a + b = tensor([5., 7., 9.])\n",
      "a - b = tensor([-3., -3., -3.])\n",
      "a * b (元素级乘法) = tensor([ 4., 10., 18.])\n",
      "a.matmul(b) (点积) = 32.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 张量的基本属性\n",
    "print(\"\\n2. 张量的基本属性：\")\n",
    "tensor = torch.randn(3, 4, 5)\n",
    "print(f\"张量形状: {tensor.shape}\")\n",
    "print(f\"张量维度数: {tensor.ndim}\")\n",
    "print(f\"张量元素总数: {tensor.numel()}\")\n",
    "print(f\"张量数据类型: {tensor.dtype}\")\n",
    "print(f\"张量所在设备: {tensor.device}\")\n",
    "\n",
    "# 张量的索引和切片\n",
    "print(\"\\n3. 张量的索引和切片：\")\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"原始张量:\\n{tensor}\")\n",
    "print(f\"第一行: {tensor[0]}\")\n",
    "print(f\"第一列: {tensor[:, 0]}\")\n",
    "print(f\"子矩阵:\\n{tensor[0:2, 1:3]}\")\n",
    "\n",
    "# 张量的数学运算\n",
    "print(\"\\n4. 张量的数学运算：\")\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "b = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "print(f\"a + b = {a + b}\")\n",
    "print(f\"a - b = {a - b}\")\n",
    "print(f\"a * b (元素级乘法) = {a * b}\")\n",
    "print(f\"a.matmul(b) (点积) = {a.matmul(b)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 张量与常量运算 ===\n",
      "张量加常量: tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n",
      "张量乘常量: tensor([[10., 20., 30.],\n",
      "        [40., 50., 60.]])\n",
      "矩阵乘法(3x2 @ 2x3): tensor([[ 9., 12., 15.],\n",
      "        [19., 26., 33.],\n",
      "        [29., 40., 51.]])\n",
      "\n",
      "=== 广播机制 ===\n",
      "张量A形状: torch.Size([2, 3])\n",
      "张量B形状: torch.Size([1, 3])\n",
      "张量相加 (广播):\n",
      " tensor([[11., 22., 33.],\n",
      "        [14., 25., 36.]])\n",
      "张量C形状: torch.Size([2, 1])\n",
      "张量A与C相乘 (广播):\n",
      " tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 张量与常量运算 ===\")\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "constant = 10\n",
    "print(\"张量加常量:\", tensor_2d + constant)\n",
    "print(\"张量乘常量:\", tensor_2d * constant)\n",
    "\n",
    "tensor_3d = torch.tensor([[1, 2],\n",
    "                           [3,4] ,\n",
    "                           [5,6]     ], dtype=torch.float32)\n",
    "print(\"矩阵乘法(3x2 @ 2x3):\", torch.matmul(tensor_3d,tensor_2d))\n",
    "\n",
    "# 广播机制 - 不同形状的张量运算\n",
    "print(\"\\n=== 广播机制 ===\")\n",
    "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)  # 形状为 (2, 3)\n",
    "tensor_b = torch.tensor([[10, 20, 30]], dtype=torch.float32)         # 形状为 (1, 3)\n",
    "print(\"张量A形状:\", tensor_a.shape)\n",
    "print(\"张量B形状:\", tensor_b.shape)\n",
    "print(\"张量相加 (广播):\\n\", tensor_a + tensor_b)\n",
    "\n",
    "# 另一个广播例子\n",
    "tensor_c = torch.tensor([[1], [2]], dtype=torch.float32)             # 形状为 (2, 1)\n",
    "print(\"张量C形状:\", tensor_c.shape)\n",
    "print(\"张量A与C相乘 (广播):\\n\", tensor_a * tensor_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. 张量的梯度计算：\n",
      "x = tensor([2.], requires_grad=True), y = x^2 = tensor([4.], grad_fn=<PowBackward0>)\n",
      "dy/dx = tensor([4.])\n",
      "\n",
      "8. 张量与NumPy的互操作：\n",
      "Tensor转NumPy: [1. 1. 1.] (类型: <class 'numpy.ndarray'>)\n",
      "NumPy转Tensor: tensor([1., 2., 3.], dtype=torch.float64) (类型: <class 'torch.Tensor'>)\n"
     ]
    }
   ],
   "source": [
    "# 张量的梯度计算（自动微分）\n",
    "print(\"张量的梯度计算：\")\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(f\"x = {x}, y = x^2 = {y}\")\n",
    "print(f\"dy/dx = {x.grad}\")\n",
    "\n",
    "# 张量与NumPy的互操作\n",
    "print(\"\\n8. 张量与NumPy的互操作：\")\n",
    "tensor = torch.ones(3)\n",
    "numpy_array = tensor.numpy()\n",
    "print(f\"Tensor转NumPy: {numpy_array} (类型: {type(numpy_array)})\")\n",
    "\n",
    "numpy_array = np.array([1.0, 2.0, 3.0])\n",
    "tensor = torch.from_numpy(numpy_array)\n",
    "print(f\"NumPy转Tensor: {tensor} (类型: {type(tensor)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
